{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import generate_codecharts\n",
    "import os\n",
    "import string\n",
    "import random\n",
    "import json \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import base64 \n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcedir = '../demo_experiment_images/' # replace this with your own images\n",
    "tutorial_source_dir = 'tutorial_images' # where tutorial images are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS for generating subject files\n",
    "num_subject_files = 3    # number of participant files to generate (= # of assignments that will be put up)    \n",
    "num_images_per_sf = 35   # number of images each participant will see (in this case, = # images in image_dir)\n",
    "num_imgs_per_tutorial = 4\n",
    "num_sentinels_per_tutorial = 2\n",
    "num_sentinels_per_sf = 5 # excluding the tutorial\n",
    "add_sentinels_to_tutorial = True\n",
    "\n",
    "ncodecharts = num_subject_files*num_images_per_sf # can be changed\n",
    "sentinel_images_per_bucket = num_subject_files*num_sentinels_per_sf # can be changed\n",
    "\n",
    "# params for generating sentinels\n",
    "target_type = \"img\" # one of fix_cross, red_dot, or img\n",
    "target_imdir = \"sentinel_target_images\"\n",
    "\n",
    "# set these parameters\n",
    "num_buckets = 1\n",
    "start_bucket_at = 0\n",
    "which_buckets = [0]  # can make this a list of specific buckets e.g., [4,5,6]\n",
    "\n",
    "rootdir = '../assets/task_data'\n",
    "if not os.path.exists(rootdir):\n",
    "    print('Creating directory %s'%(rootdir))\n",
    "    os.makedirs(rootdir)\n",
    "\n",
    "real_image_dir = os.path.join(rootdir,'real_images')\n",
    "real_CC_dir = os.path.join(rootdir,'real_CC')\n",
    "sentinel_image_dir = os.path.join(rootdir,'sentinel_images')\n",
    "sentinel_CC_dir = os.path.join(rootdir,'sentinel_CC')\n",
    "sentinel_targetim_dir = os.path.join(rootdir, 'sentinel_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory ./task_data/all_images\n",
      "len allfiles 51\n",
      "Image widths: dict_keys([640])\n",
      "Image heights: dict_keys([480])\n",
      "Padding 51 image files to dimensions: [1786,1340]...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import create_padded_image_dir\n",
    "\n",
    "all_image_dir = os.path.join(rootdir,'all_images')\n",
    "\n",
    "if not os.path.exists(all_image_dir):\n",
    "    print('Creating directory %s'%(all_image_dir))\n",
    "    os.makedirs(all_image_dir)\n",
    "    \n",
    "allfiles = []\n",
    "for ext in ('*.jpeg', '*.png', '*.jpg'):\n",
    "    allfiles.extend(glob.glob(os.path.join(sourcedir, ext)))\n",
    "print(\"len allfiles\", len(allfiles))\n",
    "    \n",
    "image_width,image_height = create_padded_image_dir.save_padded_images(all_image_dir,allfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using font size: 37\n"
     ]
    }
   ],
   "source": [
    "from generate_central_fixation_cross import save_fixation_cross\n",
    "\n",
    "save_fixation_cross(rootdir,image_width,image_height);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distribute_image_files_by_buckets import distribute_images\n",
    "\n",
    "distribute_images(all_image_dir,real_image_dir,num_buckets,start_bucket_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/2000\n",
      "100/2000\n",
      "200/2000\n",
      "300/2000\n",
      "400/2000\n",
      "500/2000\n",
      "600/2000\n",
      "700/2000\n",
      "800/2000\n",
      "900/2000\n",
      "1000/2000\n",
      "1100/2000\n",
      "1200/2000\n",
      "1300/2000\n",
      "1400/2000\n",
      "1500/2000\n",
      "1600/2000\n",
      "1700/2000\n",
      "1800/2000\n",
      "1900/2000\n"
     ]
    }
   ],
   "source": [
    "from create_codecharts_dir import create_codecharts\n",
    "\n",
    "create_codecharts(real_CC_dir,ncodecharts,image_width,image_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import generate_sentinels\n",
    "\n",
    "border_padding = 100 # used to guarantee that chosen sentinel location is not too close to border to be hard to spot\n",
    "\n",
    "generate_sentinels.generate_sentinels(sentinel_image_dir,sentinel_CC_dir,num_buckets,start_bucket_at,sentinel_images_per_bucket,\\\n",
    "                       image_width,image_height,border_padding,target_type, target_imdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory ./task_data/tutorial_images\n",
      "len allfiles 9\n",
      "Padding 9 image files to dimensions: [1786,1340]...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from generate_tutorials import generate_tutorials\n",
    "\n",
    "# inherit border_padding and fixcross styles from above cell\n",
    "border_padding = 100\n",
    "\n",
    "tutorial_image_dir = os.path.join(rootdir,'tutorial_images') # where processed tutorial images will be saved\n",
    "if not os.path.exists(tutorial_image_dir):\n",
    "    print('Creating directory %s'%(tutorial_image_dir))\n",
    "    os.makedirs(tutorial_image_dir)\n",
    "    \n",
    "allfiles = []\n",
    "for ext in ('*.jpeg', '*.png', '*.jpg'):\n",
    "    allfiles.extend(glob.glob(os.path.join(tutorial_source_dir, ext)))\n",
    "print(\"len allfiles\", len(allfiles))\n",
    "\n",
    "create_padded_image_dir.save_padded_images(tutorial_image_dir,allfiles,toplot=False,maxwidth=image_width,maxheight=image_height)\n",
    "\n",
    "# TODO: or pick a random set of images to serve as tutorial images\n",
    "N = 6 # number of images to use for tutorials (these will be sampled from to generate subject files below)\n",
    "      # note: make this larger than num_imgs_per_tutorial so not all subject files have the same tutorials\n",
    "    \n",
    "N_sent = 6 # number of sentinels to use for tutorials \n",
    "# note: if equal to num_sentinels_per_tutorial, all subject files will have the same tutorial sentinels\n",
    "\n",
    "generate_tutorials(tutorial_image_dir,rootdir,image_width,image_height,border_padding,N,target_type,target_imdir,N_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./task_data/subject_files/bucket0/subject_file_0.json\n",
      "./task_data/subject_files/bucket0/subject_file_1.json\n",
      "./task_data/subject_files/bucket0/subject_file_2.json\n",
      "./task_data/subject_files/bucket0/subject_file_3.json\n",
      "./task_data/subject_files/bucket0/subject_file_4.json\n",
      "./task_data/subject_files/bucket0/subject_file_5.json\n",
      "./task_data/subject_files/bucket0/subject_file_6.json\n",
      "./task_data/subject_files/bucket0/subject_file_7.json\n",
      "./task_data/subject_files/bucket0/subject_file_8.json\n",
      "./task_data/subject_files/bucket0/subject_file_9.json\n",
      "./task_data/subject_files/bucket0/subject_file_10.json\n",
      "./task_data/subject_files/bucket0/subject_file_11.json\n",
      "./task_data/subject_files/bucket0/subject_file_12.json\n",
      "./task_data/subject_files/bucket0/subject_file_13.json\n",
      "./task_data/subject_files/bucket0/subject_file_14.json\n",
      "./task_data/subject_files/bucket0/subject_file_15.json\n",
      "./task_data/subject_files/bucket0/subject_file_16.json\n",
      "./task_data/subject_files/bucket0/subject_file_17.json\n",
      "./task_data/subject_files/bucket0/subject_file_18.json\n",
      "./task_data/subject_files/bucket0/subject_file_19.json\n",
      "./task_data/subject_files/bucket0/subject_file_20.json\n",
      "./task_data/subject_files/bucket0/subject_file_21.json\n",
      "./task_data/subject_files/bucket0/subject_file_22.json\n",
      "./task_data/subject_files/bucket0/subject_file_23.json\n",
      "./task_data/subject_files/bucket0/subject_file_24.json\n",
      "./task_data/subject_files/bucket0/subject_file_25.json\n",
      "./task_data/subject_files/bucket0/subject_file_26.json\n",
      "./task_data/subject_files/bucket0/subject_file_27.json\n",
      "./task_data/subject_files/bucket0/subject_file_28.json\n",
      "./task_data/subject_files/bucket0/subject_file_29.json\n",
      "./task_data/subject_files/bucket0/subject_file_30.json\n",
      "./task_data/subject_files/bucket0/subject_file_31.json\n",
      "./task_data/subject_files/bucket0/subject_file_32.json\n",
      "./task_data/subject_files/bucket0/subject_file_33.json\n",
      "./task_data/subject_files/bucket0/subject_file_34.json\n",
      "./task_data/subject_files/bucket0/subject_file_35.json\n",
      "./task_data/subject_files/bucket0/subject_file_36.json\n",
      "./task_data/subject_files/bucket0/subject_file_37.json\n",
      "./task_data/subject_files/bucket0/subject_file_38.json\n",
      "./task_data/subject_files/bucket0/subject_file_39.json\n",
      "./task_data/subject_files/bucket0/subject_file_40.json\n",
      "./task_data/subject_files/bucket0/subject_file_41.json\n",
      "./task_data/subject_files/bucket0/subject_file_42.json\n",
      "./task_data/subject_files/bucket0/subject_file_43.json\n",
      "./task_data/subject_files/bucket0/subject_file_44.json\n",
      "./task_data/subject_files/bucket0/subject_file_45.json\n",
      "./task_data/subject_files/bucket0/subject_file_46.json\n",
      "./task_data/subject_files/bucket0/subject_file_47.json\n",
      "./task_data/subject_files/bucket0/subject_file_48.json\n",
      "./task_data/subject_files/bucket0/subject_file_49.json\n",
      "./task_data/subject_files/bucket0/subject_file_50.json\n",
      "./task_data/subject_files/bucket0/subject_file_51.json\n",
      "./task_data/subject_files/bucket0/subject_file_52.json\n",
      "./task_data/subject_files/bucket0/subject_file_53.json\n",
      "./task_data/subject_files/bucket0/subject_file_54.json\n",
      "./task_data/subject_files/bucket0/subject_file_55.json\n",
      "./task_data/subject_files/bucket0/subject_file_56.json\n",
      "./task_data/subject_files/bucket0/subject_file_57.json\n",
      "./task_data/subject_files/bucket0/subject_file_58.json\n",
      "./task_data/subject_files/bucket0/subject_file_59.json\n",
      "./task_data/subject_files/bucket0/subject_file_60.json\n",
      "./task_data/subject_files/bucket0/subject_file_61.json\n",
      "./task_data/subject_files/bucket0/subject_file_62.json\n",
      "./task_data/subject_files/bucket0/subject_file_63.json\n",
      "./task_data/subject_files/bucket0/subject_file_64.json\n",
      "./task_data/subject_files/bucket0/subject_file_65.json\n",
      "./task_data/subject_files/bucket0/subject_file_66.json\n",
      "./task_data/subject_files/bucket0/subject_file_67.json\n",
      "./task_data/subject_files/bucket0/subject_file_68.json\n",
      "./task_data/subject_files/bucket0/subject_file_69.json\n",
      "./task_data/subject_files/bucket0/subject_file_70.json\n",
      "./task_data/subject_files/bucket0/subject_file_71.json\n",
      "./task_data/subject_files/bucket0/subject_file_72.json\n",
      "./task_data/subject_files/bucket0/subject_file_73.json\n",
      "./task_data/subject_files/bucket0/subject_file_74.json\n",
      "./task_data/subject_files/bucket0/subject_file_75.json\n",
      "./task_data/subject_files/bucket0/subject_file_76.json\n",
      "./task_data/subject_files/bucket0/subject_file_77.json\n",
      "./task_data/subject_files/bucket0/subject_file_78.json\n",
      "./task_data/subject_files/bucket0/subject_file_79.json\n",
      "./task_data/subject_files/bucket0/subject_file_80.json\n",
      "./task_data/subject_files/bucket0/subject_file_81.json\n",
      "./task_data/subject_files/bucket0/subject_file_82.json\n",
      "./task_data/subject_files/bucket0/subject_file_83.json\n",
      "./task_data/subject_files/bucket0/subject_file_84.json\n",
      "./task_data/subject_files/bucket0/subject_file_85.json\n",
      "./task_data/subject_files/bucket0/subject_file_86.json\n",
      "./task_data/subject_files/bucket0/subject_file_87.json\n",
      "./task_data/subject_files/bucket0/subject_file_88.json\n",
      "./task_data/subject_files/bucket0/subject_file_89.json\n",
      "./task_data/subject_files/bucket0/subject_file_90.json\n",
      "./task_data/subject_files/bucket0/subject_file_91.json\n",
      "./task_data/subject_files/bucket0/subject_file_92.json\n",
      "./task_data/subject_files/bucket0/subject_file_93.json\n",
      "./task_data/subject_files/bucket0/subject_file_94.json\n",
      "./task_data/subject_files/bucket0/subject_file_95.json\n",
      "./task_data/subject_files/bucket0/subject_file_96.json\n",
      "./task_data/subject_files/bucket0/subject_file_97.json\n",
      "./task_data/subject_files/bucket0/subject_file_98.json\n",
      "./task_data/subject_files/bucket0/subject_file_99.json\n",
      "./task_data/subject_files/bucket0/subject_file_100.json\n",
      "./task_data/subject_files/bucket0/subject_file_101.json\n",
      "./task_data/subject_files/bucket0/subject_file_102.json\n",
      "./task_data/subject_files/bucket0/subject_file_103.json\n",
      "./task_data/subject_files/bucket0/subject_file_104.json\n",
      "./task_data/subject_files/bucket0/subject_file_105.json\n",
      "./task_data/subject_files/bucket0/subject_file_106.json\n",
      "./task_data/subject_files/bucket0/subject_file_107.json\n",
      "./task_data/subject_files/bucket0/subject_file_108.json\n",
      "./task_data/subject_files/bucket0/subject_file_109.json\n",
      "./task_data/subject_files/bucket0/subject_file_110.json\n",
      "./task_data/subject_files/bucket0/subject_file_111.json\n",
      "./task_data/subject_files/bucket0/subject_file_112.json\n",
      "./task_data/subject_files/bucket0/subject_file_113.json\n",
      "./task_data/subject_files/bucket0/subject_file_114.json\n",
      "./task_data/subject_files/bucket0/subject_file_115.json\n",
      "./task_data/subject_files/bucket0/subject_file_116.json\n",
      "./task_data/subject_files/bucket0/subject_file_117.json\n",
      "./task_data/subject_files/bucket0/subject_file_118.json\n",
      "./task_data/subject_files/bucket0/subject_file_119.json\n",
      "./task_data/subject_files/bucket0/subject_file_120.json\n",
      "./task_data/subject_files/bucket0/subject_file_121.json\n",
      "./task_data/subject_files/bucket0/subject_file_122.json\n",
      "./task_data/subject_files/bucket0/subject_file_123.json\n",
      "./task_data/subject_files/bucket0/subject_file_124.json\n",
      "./task_data/subject_files/bucket0/subject_file_125.json\n",
      "./task_data/subject_files/bucket0/subject_file_126.json\n",
      "./task_data/subject_files/bucket0/subject_file_127.json\n",
      "./task_data/subject_files/bucket0/subject_file_128.json\n",
      "./task_data/subject_files/bucket0/subject_file_129.json\n",
      "./task_data/subject_files/bucket0/subject_file_130.json\n",
      "./task_data/subject_files/bucket0/subject_file_131.json\n",
      "./task_data/subject_files/bucket0/subject_file_132.json\n",
      "./task_data/subject_files/bucket0/subject_file_133.json\n",
      "./task_data/subject_files/bucket0/subject_file_134.json\n",
      "./task_data/subject_files/bucket0/subject_file_135.json\n",
      "./task_data/subject_files/bucket0/subject_file_136.json\n",
      "./task_data/subject_files/bucket0/subject_file_137.json\n",
      "./task_data/subject_files/bucket0/subject_file_138.json\n",
      "./task_data/subject_files/bucket0/subject_file_139.json\n",
      "./task_data/subject_files/bucket0/subject_file_140.json\n",
      "./task_data/subject_files/bucket0/subject_file_141.json\n",
      "./task_data/subject_files/bucket0/subject_file_142.json\n",
      "./task_data/subject_files/bucket0/subject_file_143.json\n",
      "./task_data/subject_files/bucket0/subject_file_144.json\n",
      "./task_data/subject_files/bucket0/subject_file_145.json\n",
      "./task_data/subject_files/bucket0/subject_file_146.json\n",
      "./task_data/subject_files/bucket0/subject_file_147.json\n",
      "./task_data/subject_files/bucket0/subject_file_148.json\n",
      "./task_data/subject_files/bucket0/subject_file_149.json\n",
      "./task_data/subject_files/bucket0/subject_file_150.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./task_data/subject_files/bucket0/subject_file_151.json\n",
      "./task_data/subject_files/bucket0/subject_file_152.json\n",
      "./task_data/subject_files/bucket0/subject_file_153.json\n",
      "./task_data/subject_files/bucket0/subject_file_154.json\n",
      "./task_data/subject_files/bucket0/subject_file_155.json\n",
      "./task_data/subject_files/bucket0/subject_file_156.json\n",
      "./task_data/subject_files/bucket0/subject_file_157.json\n",
      "./task_data/subject_files/bucket0/subject_file_158.json\n",
      "./task_data/subject_files/bucket0/subject_file_159.json\n",
      "./task_data/subject_files/bucket0/subject_file_160.json\n",
      "./task_data/subject_files/bucket0/subject_file_161.json\n",
      "./task_data/subject_files/bucket0/subject_file_162.json\n",
      "./task_data/subject_files/bucket0/subject_file_163.json\n",
      "./task_data/subject_files/bucket0/subject_file_164.json\n",
      "./task_data/subject_files/bucket0/subject_file_165.json\n",
      "./task_data/subject_files/bucket0/subject_file_166.json\n",
      "./task_data/subject_files/bucket0/subject_file_167.json\n",
      "./task_data/subject_files/bucket0/subject_file_168.json\n",
      "./task_data/subject_files/bucket0/subject_file_169.json\n",
      "./task_data/subject_files/bucket0/subject_file_170.json\n",
      "./task_data/subject_files/bucket0/subject_file_171.json\n",
      "./task_data/subject_files/bucket0/subject_file_172.json\n",
      "./task_data/subject_files/bucket0/subject_file_173.json\n",
      "./task_data/subject_files/bucket0/subject_file_174.json\n",
      "./task_data/subject_files/bucket0/subject_file_175.json\n",
      "./task_data/subject_files/bucket0/subject_file_176.json\n",
      "./task_data/subject_files/bucket0/subject_file_177.json\n",
      "./task_data/subject_files/bucket0/subject_file_178.json\n",
      "./task_data/subject_files/bucket0/subject_file_179.json\n",
      "./task_data/subject_files/bucket0/subject_file_180.json\n",
      "./task_data/subject_files/bucket0/subject_file_181.json\n",
      "./task_data/subject_files/bucket0/subject_file_182.json\n",
      "./task_data/subject_files/bucket0/subject_file_183.json\n",
      "./task_data/subject_files/bucket0/subject_file_184.json\n",
      "./task_data/subject_files/bucket0/subject_file_185.json\n",
      "./task_data/subject_files/bucket0/subject_file_186.json\n",
      "./task_data/subject_files/bucket0/subject_file_187.json\n",
      "./task_data/subject_files/bucket0/subject_file_188.json\n",
      "./task_data/subject_files/bucket0/subject_file_189.json\n",
      "./task_data/subject_files/bucket0/subject_file_190.json\n",
      "./task_data/subject_files/bucket0/subject_file_191.json\n",
      "./task_data/subject_files/bucket0/subject_file_192.json\n",
      "./task_data/subject_files/bucket0/subject_file_193.json\n",
      "./task_data/subject_files/bucket0/subject_file_194.json\n",
      "./task_data/subject_files/bucket0/subject_file_195.json\n",
      "./task_data/subject_files/bucket0/subject_file_196.json\n",
      "./task_data/subject_files/bucket0/subject_file_197.json\n",
      "./task_data/subject_files/bucket0/subject_file_198.json\n",
      "./task_data/subject_files/bucket0/subject_file_199.json\n",
      "./task_data/subject_files/bucket0/subject_file_200.json\n",
      "./task_data/subject_files/bucket0/subject_file_201.json\n",
      "./task_data/subject_files/bucket0/subject_file_202.json\n",
      "./task_data/subject_files/bucket0/subject_file_203.json\n",
      "./task_data/subject_files/bucket0/subject_file_204.json\n",
      "./task_data/subject_files/bucket0/subject_file_205.json\n",
      "./task_data/subject_files/bucket0/subject_file_206.json\n",
      "./task_data/subject_files/bucket0/subject_file_207.json\n",
      "./task_data/subject_files/bucket0/subject_file_208.json\n",
      "./task_data/subject_files/bucket0/subject_file_209.json\n",
      "./task_data/subject_files/bucket0/subject_file_210.json\n",
      "./task_data/subject_files/bucket0/subject_file_211.json\n",
      "./task_data/subject_files/bucket0/subject_file_212.json\n",
      "./task_data/subject_files/bucket0/subject_file_213.json\n",
      "./task_data/subject_files/bucket0/subject_file_214.json\n",
      "./task_data/subject_files/bucket0/subject_file_215.json\n",
      "./task_data/subject_files/bucket0/subject_file_216.json\n",
      "./task_data/subject_files/bucket0/subject_file_217.json\n",
      "./task_data/subject_files/bucket0/subject_file_218.json\n",
      "./task_data/subject_files/bucket0/subject_file_219.json\n",
      "./task_data/subject_files/bucket0/subject_file_220.json\n",
      "./task_data/subject_files/bucket0/subject_file_221.json\n",
      "./task_data/subject_files/bucket0/subject_file_222.json\n",
      "./task_data/subject_files/bucket0/subject_file_223.json\n",
      "./task_data/subject_files/bucket0/subject_file_224.json\n",
      "./task_data/subject_files/bucket0/subject_file_225.json\n",
      "./task_data/subject_files/bucket0/subject_file_226.json\n",
      "./task_data/subject_files/bucket0/subject_file_227.json\n",
      "./task_data/subject_files/bucket0/subject_file_228.json\n",
      "./task_data/subject_files/bucket0/subject_file_229.json\n",
      "./task_data/subject_files/bucket0/subject_file_230.json\n",
      "./task_data/subject_files/bucket0/subject_file_231.json\n",
      "./task_data/subject_files/bucket0/subject_file_232.json\n",
      "./task_data/subject_files/bucket0/subject_file_233.json\n",
      "./task_data/subject_files/bucket0/subject_file_234.json\n",
      "./task_data/subject_files/bucket0/subject_file_235.json\n",
      "./task_data/subject_files/bucket0/subject_file_236.json\n",
      "./task_data/subject_files/bucket0/subject_file_237.json\n",
      "./task_data/subject_files/bucket0/subject_file_238.json\n",
      "./task_data/subject_files/bucket0/subject_file_239.json\n",
      "./task_data/subject_files/bucket0/subject_file_240.json\n",
      "./task_data/subject_files/bucket0/subject_file_241.json\n",
      "./task_data/subject_files/bucket0/subject_file_242.json\n",
      "./task_data/subject_files/bucket0/subject_file_243.json\n",
      "./task_data/subject_files/bucket0/subject_file_244.json\n",
      "./task_data/subject_files/bucket0/subject_file_245.json\n",
      "./task_data/subject_files/bucket0/subject_file_246.json\n",
      "./task_data/subject_files/bucket0/subject_file_247.json\n",
      "./task_data/subject_files/bucket0/subject_file_248.json\n",
      "./task_data/subject_files/bucket0/subject_file_249.json\n",
      "./task_data/subject_files/bucket0/subject_file_250.json\n",
      "./task_data/subject_files/bucket0/subject_file_251.json\n",
      "./task_data/subject_files/bucket0/subject_file_252.json\n",
      "./task_data/subject_files/bucket0/subject_file_253.json\n",
      "./task_data/subject_files/bucket0/subject_file_254.json\n",
      "./task_data/subject_files/bucket0/subject_file_255.json\n",
      "./task_data/subject_files/bucket0/subject_file_256.json\n",
      "./task_data/subject_files/bucket0/subject_file_257.json\n",
      "./task_data/subject_files/bucket0/subject_file_258.json\n",
      "./task_data/subject_files/bucket0/subject_file_259.json\n",
      "./task_data/subject_files/bucket0/subject_file_260.json\n",
      "./task_data/subject_files/bucket0/subject_file_261.json\n",
      "./task_data/subject_files/bucket0/subject_file_262.json\n",
      "./task_data/subject_files/bucket0/subject_file_263.json\n",
      "./task_data/subject_files/bucket0/subject_file_264.json\n",
      "./task_data/subject_files/bucket0/subject_file_265.json\n",
      "./task_data/subject_files/bucket0/subject_file_266.json\n",
      "./task_data/subject_files/bucket0/subject_file_267.json\n",
      "./task_data/subject_files/bucket0/subject_file_268.json\n",
      "./task_data/subject_files/bucket0/subject_file_269.json\n",
      "./task_data/subject_files/bucket0/subject_file_270.json\n",
      "./task_data/subject_files/bucket0/subject_file_271.json\n",
      "./task_data/subject_files/bucket0/subject_file_272.json\n",
      "./task_data/subject_files/bucket0/subject_file_273.json\n",
      "./task_data/subject_files/bucket0/subject_file_274.json\n",
      "./task_data/subject_files/bucket0/subject_file_275.json\n",
      "./task_data/subject_files/bucket0/subject_file_276.json\n",
      "./task_data/subject_files/bucket0/subject_file_277.json\n",
      "./task_data/subject_files/bucket0/subject_file_278.json\n",
      "./task_data/subject_files/bucket0/subject_file_279.json\n",
      "./task_data/subject_files/bucket0/subject_file_280.json\n",
      "./task_data/subject_files/bucket0/subject_file_281.json\n",
      "./task_data/subject_files/bucket0/subject_file_282.json\n",
      "./task_data/subject_files/bucket0/subject_file_283.json\n",
      "./task_data/subject_files/bucket0/subject_file_284.json\n",
      "./task_data/subject_files/bucket0/subject_file_285.json\n",
      "./task_data/subject_files/bucket0/subject_file_286.json\n",
      "./task_data/subject_files/bucket0/subject_file_287.json\n",
      "./task_data/subject_files/bucket0/subject_file_288.json\n",
      "./task_data/subject_files/bucket0/subject_file_289.json\n",
      "./task_data/subject_files/bucket0/subject_file_290.json\n",
      "./task_data/subject_files/bucket0/subject_file_291.json\n",
      "./task_data/subject_files/bucket0/subject_file_292.json\n",
      "./task_data/subject_files/bucket0/subject_file_293.json\n",
      "./task_data/subject_files/bucket0/subject_file_294.json\n",
      "./task_data/subject_files/bucket0/subject_file_295.json\n",
      "./task_data/subject_files/bucket0/subject_file_296.json\n",
      "./task_data/subject_files/bucket0/subject_file_297.json\n",
      "./task_data/subject_files/bucket0/subject_file_298.json\n",
      "./task_data/subject_files/bucket0/subject_file_299.json\n"
     ]
    }
   ],
   "source": [
    "start_subjects_at = 0     # where to start naming subject files at (if had already created files)\n",
    "if os.path.exists(os.path.join(rootdir,'subject_files/bucket0')):\n",
    "    subjfiles = glob.glob(os.path.join(rootdir,'subject_files/bucket0/*.json'))\n",
    "    start_subjects_at = len(subjfiles)\n",
    "\n",
    "#real_codecharts = os.listdir(real_CC_dir)\n",
    "real_codecharts = glob.glob(os.path.join(real_CC_dir,'*.jpg'))\n",
    "sentinel_codecharts = glob.glob(os.path.join(sentinel_CC_dir,'*.jpg'))\n",
    "\n",
    "with open(os.path.join(real_CC_dir,'CC_codes_full.json')) as f:\n",
    "    real_codes_data = json.load(f) # contains mapping of image path to valid codes\n",
    "\n",
    "## GENERATING SUBJECT FILES \n",
    "subjdir = os.path.join(rootdir,'subject_files')\n",
    "if not os.path.exists(subjdir):\n",
    "    os.makedirs(subjdir)\n",
    "    os.makedirs(os.path.join(rootdir,'full_subject_files'))\n",
    "    \n",
    "with open(os.path.join(rootdir,'tutorial_full.json')) as f:\n",
    "    tutorial_data = json.load(f) \n",
    "    \n",
    "tutorial_real_filenames = [fn for fn in tutorial_data.keys() if tutorial_data[fn]['flag']=='tutorial_real']\n",
    "tutorial_sentinel_filenames = [fn for fn in tutorial_data.keys() if tutorial_data[fn]['flag']=='tutorial_sentinel']\n",
    "    \n",
    "# iterate over all buckets \n",
    "for b in range(len(which_buckets)): \n",
    "    \n",
    "    bucket = 'bucket%d'%(which_buckets[b])\n",
    "    img_bucket_dir = os.path.join(real_image_dir,bucket)\n",
    "    #img_files = os.listdir(img_bucket_dir)\n",
    "    #img_files = glob.glob(os.path.join(img_bucket_dir,'*.jpg'))\n",
    "    img_files = []\n",
    "    for ext in ('*.jpeg', '*.png', '*.jpg'):\n",
    "        img_files.extend(glob.glob(os.path.join(img_bucket_dir, ext)))\n",
    "            \n",
    "    sentinel_bucket_dir = os.path.join(sentinel_image_dir,bucket)\n",
    "    #sentinel_files = os.listdir(sentinel_bucket_dir)\n",
    "    sentinel_files = glob.glob(os.path.join(sentinel_bucket_dir,'*.jpg'))\n",
    "    \n",
    "    with open(os.path.join(sentinel_bucket_dir,'sentinel_codes_full.json')) as f:\n",
    "        sentinel_codes_data = json.load(f) # contains mapping of image path to valid codes\n",
    "        \n",
    "    subjdir = os.path.join(rootdir,'subject_files',bucket)\n",
    "    if not os.path.exists(subjdir):\n",
    "        os.makedirs(subjdir)\n",
    "        os.makedirs(os.path.join(rootdir,'full_subject_files',bucket))\n",
    "    \n",
    "    # for each bucket, generate subject files \n",
    "    for i in range(num_subject_files):\n",
    "        \n",
    "        random.shuffle(img_files)\n",
    "        random.shuffle(sentinel_files)\n",
    "        random.shuffle(real_codecharts)\n",
    "        \n",
    "        # for each subject files, add real images \n",
    "        sf_data = []\n",
    "        full_sf_data = []\n",
    "\n",
    "        # ADDING TUTORIALS\n",
    "        random.shuffle(tutorial_real_filenames)\n",
    "        random.shuffle(tutorial_sentinel_filenames)\n",
    "        \n",
    "        # initialize temporary arrays, because will shuffle real & sentinel tutorial images before adding to\n",
    "        # final subject files\n",
    "        sf_data_temp = []\n",
    "        full_sf_data_temp = []\n",
    "        \n",
    "        for j in range(num_imgs_per_tutorial):\n",
    "            \n",
    "            image_data = {}\n",
    "            fn = tutorial_real_filenames[j]\n",
    "            image_data[\"image\"] = fn\n",
    "            image_data[\"codechart\"] = tutorial_data[fn]['codechart_file'] # stores codechart path \n",
    "            image_data[\"codes\"] = tutorial_data[fn]['valid_codes'] # stores valid codes \n",
    "            image_data[\"flag\"] = 'tutorial_real' # stores flag of whether we have real or sentinel image\n",
    "            full_image_data = image_data.copy() # identical to image_data but includes a key for coordinates\n",
    "            full_image_data[\"coordinates\"] = tutorial_data[fn]['coordinates'] # store (x, y) coordinate of each triplet \n",
    "            \n",
    "            sf_data_temp.append(image_data)\n",
    "            full_sf_data_temp.append(full_image_data)\n",
    "        \n",
    "        if add_sentinels_to_tutorial and num_sentinels_per_tutorial>0:\n",
    "            \n",
    "            for j in range(num_sentinels_per_tutorial):\n",
    "                image_data2 = {}\n",
    "                fn = tutorial_sentinel_filenames[j]\n",
    "                image_data2[\"image\"] = fn\n",
    "                image_data2[\"codechart\"] = tutorial_data[fn]['codechart_file'] # stores codechart path \n",
    "                image_data2[\"correct_code\"] = tutorial_data[fn]['correct_code']\n",
    "                image_data2[\"codes\"] = tutorial_data[fn]['valid_codes'] # stores valid codes \n",
    "                image_data2[\"flag\"] = 'tutorial_sentinel' # stores flag of whether we have real or sentinel image\n",
    "                full_image_data2 = image_data2.copy() # identical to image_data but includes a key for coordinates\n",
    "                full_image_data2[\"coordinate\"] = tutorial_data[fn]['coordinate'] # stores coordinate for correct code\n",
    "                full_image_data2[\"codes\"] = tutorial_data[fn]['valid_codes'] # stores valid codes \n",
    "                full_image_data2[\"coordinates\"] = tutorial_data[fn]['coordinates'] # store (x, y) coordinate of each triplet \n",
    "                \n",
    "                sf_data_temp.append(image_data2)\n",
    "                full_sf_data_temp.append(full_image_data2)\n",
    "                \n",
    "        # up to here, have sequentially added real images and then sentinel images to tutorial\n",
    "        # now want to shuffle them\n",
    "                \n",
    "        perm = np.random.permutation(len(sf_data_temp))\n",
    "        for j in range(len(perm)): # note need to make sure sf_data and full_sf_data correspond\n",
    "            sf_data.append(sf_data_temp[perm[j]])\n",
    "            full_sf_data.append(full_sf_data_temp[perm[j]])\n",
    "        \n",
    "        # ADDING REAL IMAGES \n",
    "        for j in range(num_images_per_sf): \n",
    "            image_data = {}\n",
    "            image_data[\"image\"] = img_files[j] # stores image path \n",
    "\n",
    "            # select a code chart\n",
    "            pathname = real_codecharts[j] # since shuffled, will pick up first set of random codecharts\n",
    "            \n",
    "            image_data[\"codechart\"] = pathname # stores codechart path \n",
    "            image_data[\"codes\"] = real_codes_data[pathname]['valid_codes'] # stores valid codes \n",
    "            image_data[\"flag\"] = 'real' # stores flag of whether we have real or sentinel image\n",
    "            \n",
    "            full_image_data = image_data.copy() # identical to image_data but includes a key for coordinates\n",
    "            full_image_data[\"coordinates\"] = real_codes_data[pathname]['coordinates'] # store locations - (x, y) coordinate of each triplet \n",
    "\n",
    "            sf_data.append(image_data)\n",
    "            full_sf_data.append(full_image_data)\n",
    "\n",
    "        ## ADDING SENTINEL IMAGES \n",
    "        sentinel_spacing = int(num_images_per_sf/float(num_sentinels_per_sf))\n",
    "        insertat = num_imgs_per_tutorial+num_sentinels_per_tutorial + 1; # don't insert before all the tutorial images are done\n",
    "        for j in range(num_sentinels_per_sf):\n",
    "            sentinel_image_data = {}\n",
    "            sentinel_pathname = sentinel_files[j]\n",
    "            sentinel_image_data[\"image\"] = sentinel_pathname # stores image path \n",
    "            sentinel_image_data[\"codechart\"] = sentinel_codes_data[sentinel_pathname]['codechart_file']\n",
    "            sentinel_image_data[\"correct_code\"] = sentinel_codes_data[sentinel_pathname]['correct_code']\n",
    "            sentinel_image_data[\"codes\"] = sentinel_codes_data[sentinel_pathname][\"valid_codes\"]\n",
    "            sentinel_image_data[\"flag\"] = 'sentinel' # stores flag of whether we have real or sentinel image\n",
    "            \n",
    "            # for analysis, save other attributes too\n",
    "            full_sentinel_image_data = sentinel_image_data.copy() # identical to sentinel_image_data but includes coordinate key \n",
    "            full_sentinel_image_data[\"coordinate\"] = sentinel_codes_data[sentinel_pathname][\"coordinate\"] # stores the coordinate of the correct code \n",
    "            full_sentinel_image_data[\"codes\"] = sentinel_codes_data[sentinel_pathname][\"valid_codes\"] # stores other valid codes\n",
    "            full_sentinel_image_data[\"coordinates\"] = sentinel_codes_data[sentinel_pathname][\"coordinates\"] # stores the coordinate of the valid code \n",
    "            \n",
    "            insertat = insertat + random.choice(range(sentinel_spacing-1,sentinel_spacing+2))\n",
    "            insertat = min(insertat,len(sf_data)-1)\n",
    "\n",
    "            sf_data.insert(insertat, sentinel_image_data)\n",
    "            full_sf_data.insert(insertat, full_sentinel_image_data)\n",
    "\n",
    "        # Add an image_id to each subject file entry\n",
    "        image_id = 0 # represents the index of the image in the subject file \n",
    "        for d in range(len(sf_data)): \n",
    "            sf_data[d]['index'] = image_id\n",
    "            full_sf_data[d]['index'] = image_id\n",
    "            image_id+=1\n",
    "\n",
    "        subj_num = start_subjects_at+i\n",
    "        with open(os.path.join(rootdir,'subject_files',bucket,'subject_file_%d.json'%(subj_num)), 'w') as outfile: \n",
    "            print(outfile.name)\n",
    "            json.dump(sf_data, outfile)\n",
    "        with open(os.path.join(rootdir,'full_subject_files',bucket,'subject_file_%d.json'%(subj_num)), 'w') as outfile: \n",
    "            json.dump(full_sf_data, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
