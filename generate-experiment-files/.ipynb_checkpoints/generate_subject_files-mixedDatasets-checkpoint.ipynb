{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this generate_subject_files is different in that can specify a custom number of real & sentinel images for tutorials\n",
    "# previously, assumed that would have either equal numbers of real & sentinels, or else just real images in tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import generate_codecharts\n",
    "import os\n",
    "import string\n",
    "import random\n",
    "import json \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import base64 \n",
    "import glob\n",
    "import importlib\n",
    "import create_padded_image_dir\n",
    "\n",
    "# TODO: run generate_subject_files/check_bad_img.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS for generating subject files\n",
    "num_subject_files = 100    \n",
    "num_images_per_sf = 50   \n",
    "num_imgs_per_tutorial = 3\n",
    "num_sentinels_per_tutorial = 3\n",
    "num_sentinels_per_sf = 5 # excluding the tutorial\n",
    "add_sentinels_to_tutorial = True\n",
    "\n",
    "ncodecharts = 2000 # number of codecharts to generate in total\n",
    "sentinel_images_per_bucket = 50 \n",
    "\n",
    "# params for generating sentinels\n",
    "target_type = \"img\" # one of fix_cross, red_dot, or img\n",
    "target_imdir = \"sentinel_target_images\"\n",
    "\n",
    "# set these parameters\n",
    "num_buckets = None # will set this later (to be dependent on number of images)\n",
    "start_bucket_at = 0\n",
    "which_buckets = range(10)  # can make this a list of specific buckets e.g., [4,5,6]\n",
    "\n",
    "rootdir = './task_data'\n",
    "real_image_dir = os.path.join(rootdir,'real_images')\n",
    "real_CC_dir = os.path.join(rootdir,'real_CC')\n",
    "sentinel_image_dir = os.path.join(rootdir,'sentinel_images')\n",
    "sentinel_CC_dir = os.path.join(rootdir,'sentinel_CC')\n",
    "sentinel_targetim_dir = os.path.join(rootdir, 'sentinel_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory ./task_data/all_images\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sourcedir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-60be459aa93b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mallfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'*.jpeg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mallfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msourcedir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"len allfiles\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sourcedir' is not defined"
     ]
    }
   ],
   "source": [
    "all_image_dir = os.path.join(rootdir,'all_images')\n",
    "\n",
    "# collect images from these directories\n",
    "sourcedirs = ['../../attention-code-charts-eyetracking-datasets/Selection/CAT2000trainSet/Action',\\\n",
    "              '../../attention-code-charts-eyetracking-datasets/Selection/selection_out_of_context',\\\n",
    "              '../../attention-code-charts-eyetracking-datasets/Selection/saliency-in-crowd-master/selected100']\n",
    "\n",
    "if not os.path.exists(all_image_dir):\n",
    "    print('Creating directory %s'%(all_image_dir))\n",
    "    os.makedirs(all_image_dir)\n",
    "    \n",
    "allfiles = []\n",
    "for ext in ('*.jpeg', '*.png', '*.jpg'):\n",
    "    for sourcedir in sourcedirs:\n",
    "        allfiles.extend(glob.glob(os.path.join(sourcedir, ext)))\n",
    "print(\"len allfiles\", len(allfiles))\n",
    "\n",
    "num_buckets = len(allfiles)/num_images_per_sf\n",
    "print('Will be using %d buckets'%(num_buckets))\n",
    "    \n",
    "maxwidth = 1786\n",
    "maxheight = 1340\n",
    "# to be compatible with SALICON images\n",
    "              \n",
    "image_width,image_height = create_padded_image_dir.save_padded_images(all_image_dir,allfiles,toplot=False,\\\n",
    "                                                                      maxwidth=640,maxheight=480)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_central_fixation_cross import save_fixation_cross\n",
    "\n",
    "save_fixation_cross(rootdir,image_width,image_height);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distribute_image_files_by_buckets import distribute_images\n",
    "\n",
    "distribute_images(all_image_dir,real_image_dir,num_buckets,start_bucket_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# sanity check that buckets have different images:\n",
    "temp = []\n",
    "for bnum in range(num_buckets):\n",
    "    bucketpath = os.path.join(real_image_dir,'bucket%d'%(bnum))\n",
    "    temp.extend(glob.glob(os.path.join(bucketpath,'*.jpg')))\n",
    "print('Number unique files: %d'%(len(Counter(temp).keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_codecharts_dir import create_codecharts\n",
    "\n",
    "create_codecharts(real_CC_dir,ncodecharts,image_width,image_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import generate_sentinels\n",
    "importlib.reload(generate_sentinels) \n",
    "\n",
    "border_padding = 100 # used to guarantee that chosen sentinel location is not too close to border to be hard to spot\n",
    "\n",
    "generate_sentinels.generate_sentinels(sentinel_image_dir,sentinel_CC_dir,num_buckets,start_bucket_at,sentinel_images_per_bucket,\\\n",
    "                       image_width,image_height,border_padding,target_type, target_imdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_tutorials import generate_tutorials\n",
    "\n",
    "# inherit border_padding and fixcross styles from above cell\n",
    "border_padding = 100\n",
    "tutorial_source_dir = './tutorial_images' # where tutorial images are stored\n",
    "\n",
    "tutorial_image_dir = os.path.join(rootdir,'tutorial_images') # where processed tutorial images will be saved\n",
    "if not os.path.exists(tutorial_image_dir):\n",
    "    print('Creating directory %s'%(tutorial_image_dir))\n",
    "    os.makedirs(tutorial_image_dir)\n",
    "    \n",
    "allfiles = []\n",
    "for ext in ('*.jpeg', '*.png', '*.jpg'):\n",
    "    allfiles.extend(glob.glob(os.path.join(tutorial_source_dir, ext)))\n",
    "print(\"len allfiles\", len(allfiles))\n",
    "\n",
    "create_padded_image_dir.save_padded_images(tutorial_image_dir,allfiles,toplot=False,maxwidth=image_width,maxheight=image_height)\n",
    "\n",
    "# TODO: or pick a random set of images to serve as tutorial images\n",
    "N = 6 # number of images to use for tutorials (these will be sampled from to generate subject files below)\n",
    "      # note: make this larger than num_imgs_per_tutorial so not all subject files have the same tutorials\n",
    "    \n",
    "N_sent = 100 # number of sentinels to use for tutorials \n",
    "# note: if equal to num_sentinels_per_tutorial, all subject files will have the same tutorial sentinels\n",
    "\n",
    "generate_tutorials(tutorial_image_dir,rootdir,image_width,image_height,border_padding,N,target_type,target_imdir,N_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_subjects_at = 0     # where to start naming subject files at (if had already created files)\n",
    "if os.path.exists(os.path.join(rootdir,'subject_files/bucket0')):\n",
    "    subjfiles = glob.glob(os.path.join(rootdir,'subject_files/bucket0/*.json'))\n",
    "    start_subjects_at = len(subjfiles)\n",
    "\n",
    "#real_codecharts = os.listdir(real_CC_dir)\n",
    "real_codecharts = glob.glob(os.path.join(real_CC_dir,'*.jpg'))\n",
    "sentinel_codecharts = glob.glob(os.path.join(sentinel_CC_dir,'*.jpg'))\n",
    "\n",
    "with open(os.path.join(real_CC_dir,'CC_codes_full.json')) as f:\n",
    "    real_codes_data = json.load(f) # contains mapping of image path to valid codes\n",
    "\n",
    "## GENERATING SUBJECT FILES \n",
    "subjdir = os.path.join(rootdir,'subject_files')\n",
    "if not os.path.exists(subjdir):\n",
    "    os.makedirs(subjdir)\n",
    "    os.makedirs(os.path.join(rootdir,'full_subject_files'))\n",
    "    \n",
    "with open(os.path.join(rootdir,'tutorial_full.json')) as f:\n",
    "    tutorial_data = json.load(f) \n",
    "    \n",
    "tutorial_real_filenames = [fn for fn in tutorial_data.keys() if tutorial_data[fn]['flag']=='tutorial_real']\n",
    "tutorial_sentinel_filenames = [fn for fn in tutorial_data.keys() if tutorial_data[fn]['flag']=='tutorial_sentinel']\n",
    "    \n",
    "# iterate over all buckets \n",
    "for b in range(len(which_buckets)): \n",
    "    \n",
    "    bucket = 'bucket%d'%(which_buckets[b])\n",
    "    img_bucket_dir = os.path.join(real_image_dir,bucket)\n",
    "    #img_files = os.listdir(img_bucket_dir)\n",
    "    #img_files = glob.glob(os.path.join(img_bucket_dir,'*.jpg'))\n",
    "    img_files = []\n",
    "    for ext in ('*.jpeg', '*.png', '*.jpg'):\n",
    "        img_files.extend(glob.glob(os.path.join(img_bucket_dir, ext)))\n",
    "            \n",
    "    sentinel_bucket_dir = os.path.join(sentinel_image_dir,bucket)\n",
    "    #sentinel_files = os.listdir(sentinel_bucket_dir)\n",
    "    sentinel_files = glob.glob(os.path.join(sentinel_bucket_dir,'*.jpg'))\n",
    "    \n",
    "    with open(os.path.join(sentinel_bucket_dir,'sentinel_codes_full.json')) as f:\n",
    "        sentinel_codes_data = json.load(f) # contains mapping of image path to valid codes\n",
    "        \n",
    "    subjdir = os.path.join(rootdir,'subject_files',bucket)\n",
    "    if not os.path.exists(subjdir):\n",
    "        os.makedirs(subjdir)\n",
    "        os.makedirs(os.path.join(rootdir,'full_subject_files',bucket))\n",
    "    \n",
    "    # for each bucket, generate subject files \n",
    "    for i in range(num_subject_files):\n",
    "        \n",
    "        random.shuffle(img_files)\n",
    "        random.shuffle(sentinel_files)\n",
    "        random.shuffle(real_codecharts)\n",
    "        \n",
    "        # for each subject files, add real images \n",
    "        sf_data = []\n",
    "        full_sf_data = []\n",
    "\n",
    "        # ADDING TUTORIALS\n",
    "        random.shuffle(tutorial_real_filenames)\n",
    "        random.shuffle(tutorial_sentinel_filenames)\n",
    "        \n",
    "        # initialize temporary arrays, because will shuffle real & sentinel tutorial images before adding to\n",
    "        # final subject files\n",
    "        sf_data_temp = []\n",
    "        full_sf_data_temp = []\n",
    "        \n",
    "        for j in range(num_imgs_per_tutorial):\n",
    "            \n",
    "            image_data = {}\n",
    "            fn = tutorial_real_filenames[j]\n",
    "            image_data[\"image\"] = fn\n",
    "            image_data[\"codechart\"] = tutorial_data[fn]['codechart_file'] # stores codechart path \n",
    "            image_data[\"codes\"] = tutorial_data[fn]['valid_codes'] # stores valid codes \n",
    "            image_data[\"flag\"] = 'tutorial_real' # stores flag of whether we have real or sentinel image\n",
    "            full_image_data = image_data.copy() # identical to image_data but includes a key for coordinates\n",
    "            full_image_data[\"coordinates\"] = tutorial_data[fn]['coordinates'] # store (x, y) coordinate of each triplet \n",
    "            \n",
    "            sf_data_temp.append(image_data)\n",
    "            full_sf_data_temp.append(full_image_data)\n",
    "        \n",
    "        if add_sentinels_to_tutorial and num_sentinels_per_tutorial>0:\n",
    "            \n",
    "            for j in range(num_sentinels_per_tutorial):\n",
    "                image_data2 = {}\n",
    "                fn = tutorial_sentinel_filenames[j]\n",
    "                image_data2[\"image\"] = fn\n",
    "                image_data2[\"codechart\"] = tutorial_data[fn]['codechart_file'] # stores codechart path \n",
    "                image_data2[\"correct_code\"] = tutorial_data[fn]['correct_code']\n",
    "                image_data2[\"correct_codes\"] = tutorial_data[fn]['correct_codes']\n",
    "                image_data2[\"codes\"] = tutorial_data[fn]['valid_codes'] # stores valid codes \n",
    "                image_data2[\"flag\"] = 'tutorial_sentinel' # stores flag of whether we have real or sentinel image\n",
    "                full_image_data2 = image_data2.copy() # identical to image_data but includes a key for coordinates\n",
    "                full_image_data2[\"coordinate\"] = tutorial_data[fn]['coordinate'] # stores coordinate for correct code\n",
    "                full_image_data2[\"codes\"] = tutorial_data[fn]['valid_codes'] # stores valid codes \n",
    "                full_image_data2[\"coordinates\"] = tutorial_data[fn]['coordinates'] # store (x, y) coordinate of each triplet \n",
    "                \n",
    "                sf_data_temp.append(image_data2)\n",
    "                full_sf_data_temp.append(full_image_data2)\n",
    "                \n",
    "        # up to here, have sequentially added real images and then sentinel images to tutorial\n",
    "        # now want to shuffle them\n",
    "        \n",
    "        # perm = np.random.permutation(len(sf_data_temp))\n",
    "        # modification to the above: shuffle all but the first image, because don't want to start with a sentinel\n",
    "        perm = list(range(1,len(sf_data_temp))) # ignore 0 index\n",
    "        random.shuffle(perm)\n",
    "        perm.insert(0,0) # insert index 0 and index 0\n",
    "        # ------------\n",
    "        \n",
    "        for j in range(len(perm)): # note need to make sure sf_data and full_sf_data correspond\n",
    "            sf_data.append(sf_data_temp[perm[j]])\n",
    "            full_sf_data.append(full_sf_data_temp[perm[j]])\n",
    "        \n",
    "        # ADDING REAL IMAGES \n",
    "        for j in range(num_images_per_sf): \n",
    "            image_data = {}\n",
    "            image_data[\"image\"] = img_files[j] # stores image path \n",
    "\n",
    "            # select a code chart\n",
    "            pathname = real_codecharts[j] # since shuffled, will pick up first set of random codecharts\n",
    "            \n",
    "            image_data[\"codechart\"] = pathname # stores codechart path \n",
    "            image_data[\"codes\"] = real_codes_data[pathname]['valid_codes'] # stores valid codes \n",
    "            image_data[\"flag\"] = 'real' # stores flag of whether we have real or sentinel image\n",
    "            \n",
    "            full_image_data = image_data.copy() # identical to image_data but includes a key for coordinates\n",
    "            full_image_data[\"coordinates\"] = real_codes_data[pathname]['coordinates'] # store locations - (x, y) coordinate of each triplet \n",
    "\n",
    "            sf_data.append(image_data)\n",
    "            full_sf_data.append(full_image_data)\n",
    "\n",
    "        ## ADDING SENTINEL IMAGES \n",
    "        sentinel_spacing = int(num_images_per_sf/float(num_sentinels_per_sf))\n",
    "        insertat = num_imgs_per_tutorial+num_sentinels_per_tutorial + 1; # don't insert before all the tutorial images are done\n",
    "        for j in range(num_sentinels_per_sf):\n",
    "            sentinel_image_data = {}\n",
    "            sentinel_pathname = sentinel_files[j]\n",
    "            sentinel_image_data[\"image\"] = sentinel_pathname # stores image path \n",
    "            sentinel_image_data[\"codechart\"] = sentinel_codes_data[sentinel_pathname]['codechart_file']\n",
    "            sentinel_image_data[\"correct_code\"] = sentinel_codes_data[sentinel_pathname]['correct_code']\n",
    "            sentinel_image_data[\"correct_codes\"] = sentinel_codes_data[sentinel_pathname]['correct_codes']\n",
    "            sentinel_image_data[\"codes\"] = sentinel_codes_data[sentinel_pathname][\"valid_codes\"]\n",
    "            sentinel_image_data[\"flag\"] = 'sentinel' # stores flag of whether we have real or sentinel image\n",
    "            \n",
    "            # for analysis, save other attributes too\n",
    "            full_sentinel_image_data = sentinel_image_data.copy() # identical to sentinel_image_data but includes coordinate key \n",
    "            full_sentinel_image_data[\"coordinate\"] = sentinel_codes_data[sentinel_pathname][\"coordinate\"] # stores the coordinate of the correct code \n",
    "            full_sentinel_image_data[\"codes\"] = sentinel_codes_data[sentinel_pathname][\"valid_codes\"] # stores other valid codes\n",
    "            full_sentinel_image_data[\"coordinates\"] = sentinel_codes_data[sentinel_pathname][\"coordinates\"] # stores the coordinate of the valid code \n",
    "            \n",
    "            insertat = insertat + random.choice(range(sentinel_spacing-1,sentinel_spacing+2))\n",
    "            insertat = min(insertat,len(sf_data)-1)\n",
    "\n",
    "            sf_data.insert(insertat, sentinel_image_data)\n",
    "            full_sf_data.insert(insertat, full_sentinel_image_data)\n",
    "\n",
    "        # Add an image_id to each subject file entry\n",
    "        image_id = 0 # represents the index of the image in the subject file \n",
    "        for d in range(len(sf_data)): \n",
    "            sf_data[d]['index'] = image_id\n",
    "            full_sf_data[d]['index'] = image_id\n",
    "            image_id+=1\n",
    "\n",
    "        subj_num = start_subjects_at+i\n",
    "        with open(os.path.join(rootdir,'subject_files',bucket,'subject_file_%d.json'%(subj_num)), 'w') as outfile: \n",
    "            print(outfile.name)\n",
    "            json.dump(sf_data, outfile)\n",
    "        with open(os.path.join(rootdir,'full_subject_files',bucket,'subject_file_%d.json'%(subj_num)), 'w') as outfile: \n",
    "            json.dump(full_sf_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# source: https://www.rapidtables.com/web/dev/screen-resolution-statistics.html\n",
    "dist = 40 # recommended = 30 to 50\n",
    "s_diag = 14\n",
    "hres = 1366\n",
    "vres = 768\n",
    "\n",
    "imageHeight = 700\n",
    "# imageWidth = 1000\n",
    "factor = s_diag/math.sqrt(hres^2 + vres^2);\n",
    "s1 = (hres)*factor; # width\n",
    "s2 = (vres)*factor; # height\n",
    "#temp = imageWidth*s1/hres;\n",
    "temp = imageHeight*s2/float(vres);\n",
    "ndegs = math.degrees(2*math.atan2(temp,2*d))\n",
    "print('Image height subtends %2.2f visual angle'%ndegs)\n",
    "\n",
    "numDegs = 1\n",
    "vert_1deg = (vres/s2)*d*math.tan(math.radians(numDegs));\n",
    "print('%g deg. of vertical visual angle: %2.2f pixels'%(numDegs,vert_1deg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
