{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import generate_codecharts\n",
    "import os\n",
    "import string\n",
    "import random\n",
    "import json \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import base64 \n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS for generating subject files\n",
    "num_subject_files = 100    \n",
    "num_images_per_sf = 20   \n",
    "num_tutorials_per_sf = 2  \n",
    "num_imgs_per_tutorial = 2 \n",
    "num_sentinels_per_sf = 4  \n",
    "add_sentinels_to_tutorial = False\n",
    "\n",
    "ncodecharts = 2000 # number of codecharts to generate in total\n",
    "sentinel_images_per_bucket = 500\n",
    "\n",
    "# params for generating sentinels\n",
    "target_type = \"img\" # one of fix_cross, red_dot, or img\n",
    "target_imdir = \"sentinel_target_images\"\n",
    "\n",
    "# set these parameters\n",
    "num_buckets = 1\n",
    "start_bucket_at = 0\n",
    "which_buckets = [0]  # can make this a list of specific buckets e.g., [4,5,6]\n",
    "\n",
    "rootdir = './task_data'\n",
    "real_image_dir = os.path.join(rootdir,'real_images')\n",
    "real_CC_dir = os.path.join(rootdir,'real_CC')\n",
    "sentinel_image_dir = os.path.join(rootdir,'sentinel_images')\n",
    "sentinel_CC_dir = os.path.join(rootdir,'sentinel_CC')\n",
    "sentinel_targetim_dir = os.path.join(rootdir, 'sentinel_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_width = 557\n",
    "# image_height = 722\n",
    "# image_width = 1920 \n",
    "# image_height = 1080 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len allfiles 20\n",
      "Image widths: dict_keys([556, 510, 513])\n",
      "Image heights: dict_keys([720, 721, 723])\n",
      "Padding 20 image files to dimensions: [1030,1340]...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import create_padded_image_dir\n",
    "\n",
    "all_image_dir = os.path.join(rootdir,'all_images')\n",
    "sourcedir = '../../importance_dataset/posters_validation/posters_forvalidation/'\n",
    "#sourcedir = '../../importance_dataset/predimportance/analysis/CVs_all' # take images from here\n",
    "#sourcedir = \"../../code-chart-data/debug-pilot-red-sentinels-01-02/task_data/all_images\"\n",
    "\n",
    "if not os.path.exists(all_image_dir):\n",
    "    print('Creating directory %s'%(all_image_dir))\n",
    "    os.makedirs(all_image_dir)\n",
    "    \n",
    "allfiles = []\n",
    "for ext in ('*.jpeg', '*.png', '*.jpg'):\n",
    "    allfiles.extend(glob.glob(os.path.join(sourcedir, ext)))\n",
    "print(\"len allfiles\", len(allfiles))\n",
    "    \n",
    "image_width,image_height = create_padded_image_dir.save_padded_images(all_image_dir,allfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using font size: 37\n"
     ]
    }
   ],
   "source": [
    "from generate_central_fixation_cross import save_fixation_cross\n",
    "\n",
    "save_fixation_cross(rootdir,image_width,image_height);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distribute_image_files_by_buckets import distribute_images\n",
    "\n",
    "distribute_images(all_image_dir,real_image_dir,num_buckets,start_bucket_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/2000\n",
      "100/2000\n",
      "200/2000\n",
      "300/2000\n",
      "400/2000\n",
      "500/2000\n",
      "600/2000\n",
      "700/2000\n",
      "800/2000\n",
      "900/2000\n",
      "1000/2000\n",
      "1100/2000\n",
      "1200/2000\n",
      "1300/2000\n",
      "1400/2000\n",
      "1500/2000\n",
      "1600/2000\n",
      "1700/2000\n",
      "1800/2000\n",
      "1900/2000\n"
     ]
    }
   ],
   "source": [
    "from create_codecharts_dir import create_codecharts\n",
    "\n",
    "create_codecharts(real_CC_dir,ncodecharts,image_width,image_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import generate_sentinels\n",
    "\n",
    "border_padding = 100\n",
    "\n",
    "generate_sentinels.generate_sentinels(sentinel_image_dir,sentinel_CC_dir,num_buckets,start_bucket_at,sentinel_images_per_bucket,\\\n",
    "                       image_width,image_height,border_padding,target_type, target_imdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding 4 image files to dimensions: [1030,1340]...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from generate_tutorials import generate_tutorials\n",
    "\n",
    "# inherit border_padding and fixcross styles from above cell\n",
    "border_padding = 100\n",
    "tutorial_source_dir = './task_data/tutorial_images' # directory where to take tutorial files from\n",
    "tutorial_image_dir = './task_data/tutorial_images' # where padded/resized tutorial images will be stored\n",
    "\n",
    "# TODO: or pick a random set of images to serve as tutorial images\n",
    "N = 4 # number of images to use for tutorials (these will be sampled from to generate subject files below)\n",
    "\n",
    "tutfiles = []\n",
    "for ext in ('*.jpeg', '*.png', '*.jpg'):\n",
    "    tutfiles.extend(glob.glob(os.path.join(tutorial_source_dir, ext)))\n",
    "\n",
    "create_padded_image_dir.save_padded_images(tutorial_image_dir,tutfiles,toplot=False,maxwidth=image_width,maxheight=image_height)\n",
    "\n",
    "generate_tutorials(tutorial_image_dir,rootdir,image_width,image_height,border_padding,N,target_type,target_imdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./task_data/subject_files/bucket0/subject_file_0.json\n",
      "./task_data/subject_files/bucket0/subject_file_1.json\n",
      "./task_data/subject_files/bucket0/subject_file_2.json\n",
      "./task_data/subject_files/bucket0/subject_file_3.json\n",
      "./task_data/subject_files/bucket0/subject_file_4.json\n",
      "./task_data/subject_files/bucket0/subject_file_5.json\n",
      "./task_data/subject_files/bucket0/subject_file_6.json\n",
      "./task_data/subject_files/bucket0/subject_file_7.json\n",
      "./task_data/subject_files/bucket0/subject_file_8.json\n",
      "./task_data/subject_files/bucket0/subject_file_9.json\n",
      "./task_data/subject_files/bucket0/subject_file_10.json\n",
      "./task_data/subject_files/bucket0/subject_file_11.json\n",
      "./task_data/subject_files/bucket0/subject_file_12.json\n",
      "./task_data/subject_files/bucket0/subject_file_13.json\n",
      "./task_data/subject_files/bucket0/subject_file_14.json\n",
      "./task_data/subject_files/bucket0/subject_file_15.json\n",
      "./task_data/subject_files/bucket0/subject_file_16.json\n",
      "./task_data/subject_files/bucket0/subject_file_17.json\n",
      "./task_data/subject_files/bucket0/subject_file_18.json\n",
      "./task_data/subject_files/bucket0/subject_file_19.json\n",
      "./task_data/subject_files/bucket0/subject_file_20.json\n",
      "./task_data/subject_files/bucket0/subject_file_21.json\n",
      "./task_data/subject_files/bucket0/subject_file_22.json\n",
      "./task_data/subject_files/bucket0/subject_file_23.json\n",
      "./task_data/subject_files/bucket0/subject_file_24.json\n",
      "./task_data/subject_files/bucket0/subject_file_25.json\n",
      "./task_data/subject_files/bucket0/subject_file_26.json\n",
      "./task_data/subject_files/bucket0/subject_file_27.json\n",
      "./task_data/subject_files/bucket0/subject_file_28.json\n",
      "./task_data/subject_files/bucket0/subject_file_29.json\n",
      "./task_data/subject_files/bucket0/subject_file_30.json\n",
      "./task_data/subject_files/bucket0/subject_file_31.json\n",
      "./task_data/subject_files/bucket0/subject_file_32.json\n",
      "./task_data/subject_files/bucket0/subject_file_33.json\n",
      "./task_data/subject_files/bucket0/subject_file_34.json\n",
      "./task_data/subject_files/bucket0/subject_file_35.json\n",
      "./task_data/subject_files/bucket0/subject_file_36.json\n",
      "./task_data/subject_files/bucket0/subject_file_37.json\n",
      "./task_data/subject_files/bucket0/subject_file_38.json\n",
      "./task_data/subject_files/bucket0/subject_file_39.json\n",
      "./task_data/subject_files/bucket0/subject_file_40.json\n",
      "./task_data/subject_files/bucket0/subject_file_41.json\n",
      "./task_data/subject_files/bucket0/subject_file_42.json\n",
      "./task_data/subject_files/bucket0/subject_file_43.json\n",
      "./task_data/subject_files/bucket0/subject_file_44.json\n",
      "./task_data/subject_files/bucket0/subject_file_45.json\n",
      "./task_data/subject_files/bucket0/subject_file_46.json\n",
      "./task_data/subject_files/bucket0/subject_file_47.json\n",
      "./task_data/subject_files/bucket0/subject_file_48.json\n",
      "./task_data/subject_files/bucket0/subject_file_49.json\n",
      "./task_data/subject_files/bucket0/subject_file_50.json\n",
      "./task_data/subject_files/bucket0/subject_file_51.json\n",
      "./task_data/subject_files/bucket0/subject_file_52.json\n",
      "./task_data/subject_files/bucket0/subject_file_53.json\n",
      "./task_data/subject_files/bucket0/subject_file_54.json\n",
      "./task_data/subject_files/bucket0/subject_file_55.json\n",
      "./task_data/subject_files/bucket0/subject_file_56.json\n",
      "./task_data/subject_files/bucket0/subject_file_57.json\n",
      "./task_data/subject_files/bucket0/subject_file_58.json\n",
      "./task_data/subject_files/bucket0/subject_file_59.json\n",
      "./task_data/subject_files/bucket0/subject_file_60.json\n",
      "./task_data/subject_files/bucket0/subject_file_61.json\n",
      "./task_data/subject_files/bucket0/subject_file_62.json\n",
      "./task_data/subject_files/bucket0/subject_file_63.json\n",
      "./task_data/subject_files/bucket0/subject_file_64.json\n",
      "./task_data/subject_files/bucket0/subject_file_65.json\n",
      "./task_data/subject_files/bucket0/subject_file_66.json\n",
      "./task_data/subject_files/bucket0/subject_file_67.json\n",
      "./task_data/subject_files/bucket0/subject_file_68.json\n",
      "./task_data/subject_files/bucket0/subject_file_69.json\n",
      "./task_data/subject_files/bucket0/subject_file_70.json\n",
      "./task_data/subject_files/bucket0/subject_file_71.json\n",
      "./task_data/subject_files/bucket0/subject_file_72.json\n",
      "./task_data/subject_files/bucket0/subject_file_73.json\n",
      "./task_data/subject_files/bucket0/subject_file_74.json\n",
      "./task_data/subject_files/bucket0/subject_file_75.json\n",
      "./task_data/subject_files/bucket0/subject_file_76.json\n",
      "./task_data/subject_files/bucket0/subject_file_77.json\n",
      "./task_data/subject_files/bucket0/subject_file_78.json\n",
      "./task_data/subject_files/bucket0/subject_file_79.json\n",
      "./task_data/subject_files/bucket0/subject_file_80.json\n",
      "./task_data/subject_files/bucket0/subject_file_81.json\n",
      "./task_data/subject_files/bucket0/subject_file_82.json\n",
      "./task_data/subject_files/bucket0/subject_file_83.json\n",
      "./task_data/subject_files/bucket0/subject_file_84.json\n",
      "./task_data/subject_files/bucket0/subject_file_85.json\n",
      "./task_data/subject_files/bucket0/subject_file_86.json\n",
      "./task_data/subject_files/bucket0/subject_file_87.json\n",
      "./task_data/subject_files/bucket0/subject_file_88.json\n",
      "./task_data/subject_files/bucket0/subject_file_89.json\n",
      "./task_data/subject_files/bucket0/subject_file_90.json\n",
      "./task_data/subject_files/bucket0/subject_file_91.json\n",
      "./task_data/subject_files/bucket0/subject_file_92.json\n",
      "./task_data/subject_files/bucket0/subject_file_93.json\n",
      "./task_data/subject_files/bucket0/subject_file_94.json\n",
      "./task_data/subject_files/bucket0/subject_file_95.json\n",
      "./task_data/subject_files/bucket0/subject_file_96.json\n",
      "./task_data/subject_files/bucket0/subject_file_97.json\n",
      "./task_data/subject_files/bucket0/subject_file_98.json\n",
      "./task_data/subject_files/bucket0/subject_file_99.json\n"
     ]
    }
   ],
   "source": [
    "start_subjects_at = 0     # where to start naming subject files at (if had already created files)\n",
    "if os.path.exists(os.path.join(rootdir,'subject_files/bucket0')):\n",
    "    subjfiles = glob.glob(os.path.join(rootdir,'subject_files/bucket0/*.json'))\n",
    "    start_subjects_at = len(subjfiles)\n",
    "\n",
    "#real_codecharts = os.listdir(real_CC_dir)\n",
    "real_codecharts = glob.glob(os.path.join(real_CC_dir,'*.jpg'))\n",
    "sentinel_codecharts = glob.glob(os.path.join(sentinel_CC_dir,'*.jpg'))\n",
    "\n",
    "with open(os.path.join(real_CC_dir,'CC_codes_full.json')) as f:\n",
    "    real_codes_data = json.load(f) # contains mapping of image path to valid codes\n",
    "\n",
    "## GENERATING SUBJECT FILES \n",
    "subjdir = os.path.join(rootdir,'subject_files')\n",
    "if not os.path.exists(subjdir):\n",
    "    os.makedirs(subjdir)\n",
    "    os.makedirs(os.path.join(rootdir,'full_subject_files'))\n",
    "    \n",
    "with open(os.path.join(rootdir,'tutorial_full.json')) as f:\n",
    "    tutorial_data = json.load(f) \n",
    "    \n",
    "tutorial_real_filenames = [fn for fn in tutorial_data.keys() if tutorial_data[fn]['flag']=='tutorial_real']\n",
    "tutorial_sentinel_filenames = [fn for fn in tutorial_data.keys() if tutorial_data[fn]['flag']=='tutorial_sentinel']\n",
    "    \n",
    "# iterate over all buckets \n",
    "for b in range(len(which_buckets)): \n",
    "    \n",
    "    bucket = 'bucket%d'%(which_buckets[b])\n",
    "    img_bucket_dir = os.path.join(real_image_dir,bucket)\n",
    "    #img_files = os.listdir(img_bucket_dir)\n",
    "    #img_files = glob.glob(os.path.join(img_bucket_dir,'*.jpg'))\n",
    "    img_files = []\n",
    "    for ext in ('*.jpeg', '*.png', '*.jpg'):\n",
    "        img_files.extend(glob.glob(os.path.join(img_bucket_dir, ext)))\n",
    "            \n",
    "    sentinel_bucket_dir = os.path.join(sentinel_image_dir,bucket)\n",
    "    #sentinel_files = os.listdir(sentinel_bucket_dir)\n",
    "    sentinel_files = glob.glob(os.path.join(sentinel_bucket_dir,'*.jpg'))\n",
    "    \n",
    "    with open(os.path.join(sentinel_bucket_dir,'sentinel_codes_full.json')) as f:\n",
    "        sentinel_codes_data = json.load(f) # contains mapping of image path to valid codes\n",
    "        \n",
    "    subjdir = os.path.join(rootdir,'subject_files',bucket)\n",
    "    if not os.path.exists(subjdir):\n",
    "        os.makedirs(subjdir)\n",
    "        os.makedirs(os.path.join(rootdir,'full_subject_files',bucket))\n",
    "    \n",
    "    # for each bucket, generate subject files \n",
    "    for i in range(num_subject_files):\n",
    "        \n",
    "        random.shuffle(img_files)\n",
    "        random.shuffle(sentinel_files)\n",
    "        random.shuffle(real_codecharts)\n",
    "        \n",
    "        # for each subject files, add real images \n",
    "        sf_data = []\n",
    "        full_sf_data = []\n",
    "\n",
    "        # ADDING TUTORIALS\n",
    "        random.shuffle(tutorial_real_filenames)\n",
    "        random.shuffle(tutorial_sentinel_filenames)\n",
    "        \n",
    "        if add_sentinels_to_tutorial:\n",
    "            N = num_tutorials_per_sf\n",
    "        else:\n",
    "            N = num_tutorials_per_sf*num_imgs_per_tutorial\n",
    "        \n",
    "        for j in range(N):\n",
    "            \n",
    "            image_data = {}\n",
    "            fn = tutorial_real_filenames[j]\n",
    "            image_data[\"image\"] = fn\n",
    "            image_data[\"codechart\"] = tutorial_data[fn]['codechart_file'] # stores codechart path \n",
    "            image_data[\"codes\"] = tutorial_data[fn]['valid_codes'] # stores valid codes \n",
    "            image_data[\"flag\"] = 'tutorial_real' # stores flag of whether we have real or sentinel image\n",
    "            full_image_data = image_data.copy() # identical to image_data but includes a key for coordinates\n",
    "            full_image_data[\"coordinates\"] = tutorial_data[fn]['coordinates'] # store (x, y) coordinate of each triplet \n",
    "            \n",
    "            if add_sentinels_to_tutorial:\n",
    "                image_data2 = {}\n",
    "                fn = tutorial_sentinel_filenames[j]\n",
    "                image_data2[\"image\"] = fn\n",
    "                image_data2[\"codechart\"] = tutorial_data[fn]['codechart_file'] # stores codechart path \n",
    "                image_data2[\"correct_code\"] = tutorial_data[fn]['correct_code']\n",
    "                image_data2[\"codes\"] = tutorial_data[fn]['valid_codes'] # stores valid codes \n",
    "                image_data2[\"flag\"] = 'tutorial_sentinel' # stores flag of whether we have real or sentinel image\n",
    "                full_image_data2 = image_data2.copy() # identical to image_data but includes a key for coordinates\n",
    "                full_image_data2[\"coordinate\"] = tutorial_data[fn]['coordinate'] # stores coordinate for correct code\n",
    "                full_image_data2[\"codes\"] = tutorial_data[fn]['valid_codes'] # stores valid codes \n",
    "                full_image_data2[\"coordinates\"] = tutorial_data[fn]['coordinates'] # store (x, y) coordinate of each triplet \n",
    "            \n",
    "                # randomize whether real or sentinel image comes first in the given tutorial\n",
    "                choice = random.choice([0,1])\n",
    "                if choice==0:\n",
    "                    sf_data.append(image_data)\n",
    "                    full_sf_data.append(full_image_data)\n",
    "                    sf_data.append(image_data2)\n",
    "                    full_sf_data.append(full_image_data2)\n",
    "                else:\n",
    "                    sf_data.append(image_data2)\n",
    "                    full_sf_data.append(full_image_data2)\n",
    "                    sf_data.append(image_data)\n",
    "                    full_sf_data.append(full_image_data)\n",
    "            else:\n",
    "                sf_data.append(image_data)\n",
    "                full_sf_data.append(full_image_data)\n",
    "            \n",
    "\n",
    "        # ADDING REAL IMAGES \n",
    "        for j in range(num_images_per_sf): \n",
    "            image_data = {}\n",
    "            image_data[\"image\"] = img_files[j] # stores image path \n",
    "\n",
    "            # select a code chart\n",
    "            pathname = real_codecharts[j] # since shuffled, will pick up first set of random codecharts\n",
    "            \n",
    "            image_data[\"codechart\"] = pathname # stores codechart path \n",
    "            image_data[\"codes\"] = real_codes_data[pathname]['valid_codes'] # stores valid codes \n",
    "            image_data[\"flag\"] = 'real' # stores flag of whether we have real or sentinel image\n",
    "            \n",
    "            full_image_data = image_data.copy() # identical to image_data but includes a key for coordinates\n",
    "            full_image_data[\"coordinates\"] = real_codes_data[pathname]['coordinates'] # store locations - (x, y) coordinate of each triplet \n",
    "\n",
    "            sf_data.append(image_data)\n",
    "            full_sf_data.append(full_image_data)\n",
    "\n",
    "        ## ADDING SENTINEL IMAGES \n",
    "        sentinel_spacing = int(num_images_per_sf/float(num_sentinels_per_sf))\n",
    "        insertat = num_tutorials_per_sf*num_imgs_per_tutorial + 1; # don't insert before all the tutorial images are done\n",
    "        for j in range(num_sentinels_per_sf):\n",
    "            sentinel_image_data = {}\n",
    "            sentinel_pathname = sentinel_files[j]\n",
    "            sentinel_image_data[\"image\"] = sentinel_pathname # stores image path \n",
    "            sentinel_image_data[\"codechart\"] = sentinel_codes_data[sentinel_pathname]['codechart_file']\n",
    "            sentinel_image_data[\"correct_code\"] = sentinel_codes_data[sentinel_pathname]['correct_code']\n",
    "            sentinel_image_data[\"codes\"] = sentinel_codes_data[sentinel_pathname][\"valid_codes\"]\n",
    "            sentinel_image_data[\"flag\"] = 'sentinel' # stores flag of whether we have real or sentinel image\n",
    "            \n",
    "            # for analysis, save other attributes too\n",
    "            full_sentinel_image_data = sentinel_image_data.copy() # identical to sentinel_image_data but includes coordinate key \n",
    "            full_sentinel_image_data[\"coordinate\"] = sentinel_codes_data[sentinel_pathname][\"coordinate\"] # stores the coordinate of the correct code \n",
    "            full_sentinel_image_data[\"codes\"] = sentinel_codes_data[sentinel_pathname][\"valid_codes\"] # stores other valid codes\n",
    "            full_sentinel_image_data[\"coordinates\"] = sentinel_codes_data[sentinel_pathname][\"coordinates\"] # stores the coordinate of the valid code \n",
    "            \n",
    "            insertat = insertat + random.choice(range(sentinel_spacing-1,sentinel_spacing+2))\n",
    "            insertat = min(insertat,len(sf_data))\n",
    "\n",
    "            sf_data.insert(insertat, sentinel_image_data)\n",
    "            full_sf_data.insert(insertat, full_sentinel_image_data)\n",
    "\n",
    "        # Add an image_id to each subject file entry\n",
    "        image_id = 0 # represents the index of the image in the subject file \n",
    "        for d in range(len(sf_data)): \n",
    "            sf_data[d]['index'] = image_id\n",
    "            full_sf_data[d]['index'] = image_id\n",
    "            image_id+=1\n",
    "\n",
    "        subj_num = start_subjects_at+i\n",
    "        with open(os.path.join(rootdir,'subject_files',bucket,'subject_file_%d.json'%(subj_num)), 'w') as outfile: \n",
    "            print(outfile.name)\n",
    "            json.dump(sf_data, outfile)\n",
    "        with open(os.path.join(rootdir,'full_subject_files',bucket,'subject_file_%d.json'%(subj_num)), 'w') as outfile: \n",
    "            json.dump(full_sf_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
