{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import generate_codecharts\n",
    "import os\n",
    "import string\n",
    "import random\n",
    "import json \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import base64 \n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcedir = '../demo_experiment_images/' # replace this with your own images\n",
    "tutorial_source_dir = 'tutorial_images' # where tutorial images are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory ../assets/task_data\n"
     ]
    }
   ],
   "source": [
    "# PARAMETERS for generating subject files\n",
    "num_subject_files = 3    # number of participant files to generate (= # of assignments that will be put up)    \n",
    "num_images_per_sf = 35   # number of images each participant will see (in this case, = # images in image_dir)\n",
    "num_imgs_per_tutorial = 4\n",
    "num_sentinels_per_tutorial = 2\n",
    "num_sentinels_per_sf = 5 # excluding the tutorial\n",
    "add_sentinels_to_tutorial = True\n",
    "\n",
    "ncodecharts = num_subject_files*num_images_per_sf # can be changed\n",
    "sentinel_images_per_bucket = num_subject_files*num_sentinels_per_sf # can be changed\n",
    "\n",
    "# params for generating sentinels\n",
    "target_type = \"img\" # one of fix_cross, red_dot, or img\n",
    "target_imdir = \"sentinel_target_images\"\n",
    "\n",
    "# set these parameters\n",
    "num_buckets = 1\n",
    "start_bucket_at = 0\n",
    "which_buckets = [0]  # can make this a list of specific buckets e.g., [4,5,6]\n",
    "\n",
    "rootdir = '../assets/task_data'\n",
    "if not os.path.exists(rootdir):\n",
    "    print('Creating directory %s'%(rootdir))\n",
    "    os.makedirs(rootdir)\n",
    "\n",
    "real_image_dir = os.path.join(rootdir,'real_images')\n",
    "real_CC_dir = os.path.join(rootdir,'real_CC')\n",
    "sentinel_image_dir = os.path.join(rootdir,'sentinel_images')\n",
    "sentinel_CC_dir = os.path.join(rootdir,'sentinel_CC')\n",
    "sentinel_targetim_dir = os.path.join(rootdir, 'sentinel_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory ../assets/task_data/all_images\n",
      "len allfiles 35\n",
      "Image widths: dict_keys([1920])\n",
      "Image heights: dict_keys([1080])\n",
      "Padding 35 image files to dimensions: [1920,1080]...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import create_padded_image_dir\n",
    "\n",
    "all_image_dir = os.path.join(rootdir,'all_images')\n",
    "\n",
    "if not os.path.exists(all_image_dir):\n",
    "    print('Creating directory %s'%(all_image_dir))\n",
    "    os.makedirs(all_image_dir)\n",
    "    \n",
    "allfiles = []\n",
    "for ext in ('*.jpeg', '*.png', '*.jpg'):\n",
    "    allfiles.extend(glob.glob(os.path.join(sourcedir, ext)))\n",
    "print(\"len allfiles\", len(allfiles))\n",
    "    \n",
    "image_width,image_height = create_padded_image_dir.save_padded_images(all_image_dir,allfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using font size: 30\n"
     ]
    }
   ],
   "source": [
    "from generate_central_fixation_cross import save_fixation_cross\n",
    "\n",
    "save_fixation_cross(rootdir,image_width,image_height);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distribute_image_files_by_buckets import distribute_images\n",
    "\n",
    "distribute_images(all_image_dir,real_image_dir,num_buckets,start_bucket_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/105\n",
      "100/105\n"
     ]
    }
   ],
   "source": [
    "from create_codecharts_dir import create_codecharts\n",
    "\n",
    "create_codecharts(real_CC_dir,ncodecharts,image_width,image_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import generate_sentinels\n",
    "\n",
    "border_padding = 100 # used to guarantee that chosen sentinel location is not too close to border to be hard to spot\n",
    "\n",
    "generate_sentinels.generate_sentinels(sentinel_image_dir,sentinel_CC_dir,num_buckets,start_bucket_at,sentinel_images_per_bucket,\\\n",
    "                       image_width,image_height,border_padding,target_type, target_imdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory ../assets/task_data/tutorial_images\n",
      "len allfiles 9\n",
      "Padding 9 image files to dimensions: [1920,1080]...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from generate_tutorials import generate_tutorials\n",
    "\n",
    "# inherit border_padding and fixcross styles from above cell\n",
    "border_padding = 100\n",
    "\n",
    "tutorial_image_dir = os.path.join(rootdir,'tutorial_images') # where processed tutorial images will be saved\n",
    "if not os.path.exists(tutorial_image_dir):\n",
    "    print('Creating directory %s'%(tutorial_image_dir))\n",
    "    os.makedirs(tutorial_image_dir)\n",
    "    \n",
    "allfiles = []\n",
    "for ext in ('*.jpeg', '*.png', '*.jpg'):\n",
    "    allfiles.extend(glob.glob(os.path.join(tutorial_source_dir, ext)))\n",
    "print(\"len allfiles\", len(allfiles))\n",
    "\n",
    "create_padded_image_dir.save_padded_images(tutorial_image_dir,allfiles,toplot=False,maxwidth=image_width,maxheight=image_height)\n",
    "\n",
    "# TODO: or pick a random set of images to serve as tutorial images\n",
    "N = 6 # number of images to use for tutorials (these will be sampled from to generate subject files below)\n",
    "      # note: make this larger than num_imgs_per_tutorial so not all subject files have the same tutorials\n",
    "    \n",
    "N_sent = 6 # number of sentinels to use for tutorials \n",
    "# note: if equal to num_sentinels_per_tutorial, all subject files will have the same tutorial sentinels\n",
    "\n",
    "generate_tutorials(tutorial_image_dir,rootdir,image_width,image_height,border_padding,N,target_type,target_imdir,N_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../assets/task_data/subject_files/bucket0/subject_file_0.json\n",
      "../assets/task_data/subject_files/bucket0/subject_file_1.json\n",
      "../assets/task_data/subject_files/bucket0/subject_file_2.json\n"
     ]
    }
   ],
   "source": [
    "start_subjects_at = 0     # where to start naming subject files at (if had already created files)\n",
    "if os.path.exists(os.path.join(rootdir,'subject_files/bucket0')):\n",
    "    subjfiles = glob.glob(os.path.join(rootdir,'subject_files/bucket0/*.json'))\n",
    "    start_subjects_at = len(subjfiles)\n",
    "\n",
    "#real_codecharts = os.listdir(real_CC_dir)\n",
    "real_codecharts = glob.glob(os.path.join(real_CC_dir,'*.jpg'))\n",
    "sentinel_codecharts = glob.glob(os.path.join(sentinel_CC_dir,'*.jpg'))\n",
    "\n",
    "with open(os.path.join(real_CC_dir,'CC_codes_full.json')) as f:\n",
    "    real_codes_data = json.load(f) # contains mapping of image path to valid codes\n",
    "\n",
    "## GENERATING SUBJECT FILES \n",
    "subjdir = os.path.join(rootdir,'subject_files')\n",
    "if not os.path.exists(subjdir):\n",
    "    os.makedirs(subjdir)\n",
    "    os.makedirs(os.path.join(rootdir,'full_subject_files'))\n",
    "    \n",
    "with open(os.path.join(rootdir,'tutorial_full.json')) as f:\n",
    "    tutorial_data = json.load(f) \n",
    "    \n",
    "tutorial_real_filenames = [fn for fn in tutorial_data.keys() if tutorial_data[fn]['flag']=='tutorial_real']\n",
    "tutorial_sentinel_filenames = [fn for fn in tutorial_data.keys() if tutorial_data[fn]['flag']=='tutorial_sentinel']\n",
    "    \n",
    "# iterate over all buckets \n",
    "for b in range(len(which_buckets)): \n",
    "    \n",
    "    bucket = 'bucket%d'%(which_buckets[b])\n",
    "    img_bucket_dir = os.path.join(real_image_dir,bucket)\n",
    "    #img_files = os.listdir(img_bucket_dir)\n",
    "    #img_files = glob.glob(os.path.join(img_bucket_dir,'*.jpg'))\n",
    "    img_files = []\n",
    "    for ext in ('*.jpeg', '*.png', '*.jpg'):\n",
    "        img_files.extend(glob.glob(os.path.join(img_bucket_dir, ext)))\n",
    "            \n",
    "    sentinel_bucket_dir = os.path.join(sentinel_image_dir,bucket)\n",
    "    #sentinel_files = os.listdir(sentinel_bucket_dir)\n",
    "    sentinel_files = glob.glob(os.path.join(sentinel_bucket_dir,'*.jpg'))\n",
    "    \n",
    "    with open(os.path.join(sentinel_bucket_dir,'sentinel_codes_full.json')) as f:\n",
    "        sentinel_codes_data = json.load(f) # contains mapping of image path to valid codes\n",
    "        \n",
    "    subjdir = os.path.join(rootdir,'subject_files',bucket)\n",
    "    if not os.path.exists(subjdir):\n",
    "        os.makedirs(subjdir)\n",
    "        os.makedirs(os.path.join(rootdir,'full_subject_files',bucket))\n",
    "    \n",
    "    # for each bucket, generate subject files \n",
    "    for i in range(num_subject_files):\n",
    "        \n",
    "        random.shuffle(img_files)\n",
    "        random.shuffle(sentinel_files)\n",
    "        random.shuffle(real_codecharts)\n",
    "        \n",
    "        # for each subject files, add real images \n",
    "        sf_data = []\n",
    "        full_sf_data = []\n",
    "\n",
    "        # ADDING TUTORIALS\n",
    "        random.shuffle(tutorial_real_filenames)\n",
    "        random.shuffle(tutorial_sentinel_filenames)\n",
    "        \n",
    "        # initialize temporary arrays, because will shuffle real & sentinel tutorial images before adding to\n",
    "        # final subject files\n",
    "        sf_data_temp = []\n",
    "        full_sf_data_temp = []\n",
    "        \n",
    "        for j in range(num_imgs_per_tutorial):\n",
    "            \n",
    "            image_data = {}\n",
    "            fn = tutorial_real_filenames[j]\n",
    "            image_data[\"image\"] = fn\n",
    "            image_data[\"codechart\"] = tutorial_data[fn]['codechart_file'] # stores codechart path \n",
    "            image_data[\"codes\"] = tutorial_data[fn]['valid_codes'] # stores valid codes \n",
    "            image_data[\"flag\"] = 'tutorial_real' # stores flag of whether we have real or sentinel image\n",
    "            full_image_data = image_data.copy() # identical to image_data but includes a key for coordinates\n",
    "            full_image_data[\"coordinates\"] = tutorial_data[fn]['coordinates'] # store (x, y) coordinate of each triplet \n",
    "            \n",
    "            sf_data_temp.append(image_data)\n",
    "            full_sf_data_temp.append(full_image_data)\n",
    "        \n",
    "        if add_sentinels_to_tutorial and num_sentinels_per_tutorial>0:\n",
    "            \n",
    "            for j in range(num_sentinels_per_tutorial):\n",
    "                image_data2 = {}\n",
    "                fn = tutorial_sentinel_filenames[j]\n",
    "                image_data2[\"image\"] = fn\n",
    "                image_data2[\"codechart\"] = tutorial_data[fn]['codechart_file'] # stores codechart path \n",
    "                image_data2[\"correct_code\"] = tutorial_data[fn]['correct_code']\n",
    "                image_data2[\"codes\"] = tutorial_data[fn]['valid_codes'] # stores valid codes \n",
    "                image_data2[\"flag\"] = 'tutorial_sentinel' # stores flag of whether we have real or sentinel image\n",
    "                full_image_data2 = image_data2.copy() # identical to image_data but includes a key for coordinates\n",
    "                full_image_data2[\"coordinate\"] = tutorial_data[fn]['coordinate'] # stores coordinate for correct code\n",
    "                full_image_data2[\"codes\"] = tutorial_data[fn]['valid_codes'] # stores valid codes \n",
    "                full_image_data2[\"coordinates\"] = tutorial_data[fn]['coordinates'] # store (x, y) coordinate of each triplet \n",
    "                \n",
    "                sf_data_temp.append(image_data2)\n",
    "                full_sf_data_temp.append(full_image_data2)\n",
    "                \n",
    "        # up to here, have sequentially added real images and then sentinel images to tutorial\n",
    "        # now want to shuffle them\n",
    "                \n",
    "        perm = np.random.permutation(len(sf_data_temp))\n",
    "        for j in range(len(perm)): # note need to make sure sf_data and full_sf_data correspond\n",
    "            sf_data.append(sf_data_temp[perm[j]])\n",
    "            full_sf_data.append(full_sf_data_temp[perm[j]])\n",
    "        \n",
    "        # ADDING REAL IMAGES \n",
    "        for j in range(num_images_per_sf): \n",
    "            image_data = {}\n",
    "            image_data[\"image\"] = img_files[j] # stores image path \n",
    "\n",
    "            # select a code chart\n",
    "            pathname = real_codecharts[j] # since shuffled, will pick up first set of random codecharts\n",
    "            \n",
    "            image_data[\"codechart\"] = pathname # stores codechart path \n",
    "            image_data[\"codes\"] = real_codes_data[pathname]['valid_codes'] # stores valid codes \n",
    "            image_data[\"flag\"] = 'real' # stores flag of whether we have real or sentinel image\n",
    "            \n",
    "            full_image_data = image_data.copy() # identical to image_data but includes a key for coordinates\n",
    "            full_image_data[\"coordinates\"] = real_codes_data[pathname]['coordinates'] # store locations - (x, y) coordinate of each triplet \n",
    "\n",
    "            sf_data.append(image_data)\n",
    "            full_sf_data.append(full_image_data)\n",
    "\n",
    "        ## ADDING SENTINEL IMAGES \n",
    "        sentinel_spacing = int(num_images_per_sf/float(num_sentinels_per_sf))\n",
    "        insertat = num_imgs_per_tutorial+num_sentinels_per_tutorial + 1; # don't insert before all the tutorial images are done\n",
    "        for j in range(num_sentinels_per_sf):\n",
    "            sentinel_image_data = {}\n",
    "            sentinel_pathname = sentinel_files[j]\n",
    "            sentinel_image_data[\"image\"] = sentinel_pathname # stores image path \n",
    "            sentinel_image_data[\"codechart\"] = sentinel_codes_data[sentinel_pathname]['codechart_file']\n",
    "            sentinel_image_data[\"correct_code\"] = sentinel_codes_data[sentinel_pathname]['correct_code']\n",
    "            sentinel_image_data[\"codes\"] = sentinel_codes_data[sentinel_pathname][\"valid_codes\"]\n",
    "            sentinel_image_data[\"flag\"] = 'sentinel' # stores flag of whether we have real or sentinel image\n",
    "            \n",
    "            # for analysis, save other attributes too\n",
    "            full_sentinel_image_data = sentinel_image_data.copy() # identical to sentinel_image_data but includes coordinate key \n",
    "            full_sentinel_image_data[\"coordinate\"] = sentinel_codes_data[sentinel_pathname][\"coordinate\"] # stores the coordinate of the correct code \n",
    "            full_sentinel_image_data[\"codes\"] = sentinel_codes_data[sentinel_pathname][\"valid_codes\"] # stores other valid codes\n",
    "            full_sentinel_image_data[\"coordinates\"] = sentinel_codes_data[sentinel_pathname][\"coordinates\"] # stores the coordinate of the valid code \n",
    "            \n",
    "            insertat = insertat + random.choice(range(sentinel_spacing-1,sentinel_spacing+2))\n",
    "            insertat = min(insertat,len(sf_data)-1)\n",
    "\n",
    "            sf_data.insert(insertat, sentinel_image_data)\n",
    "            full_sf_data.insert(insertat, full_sentinel_image_data)\n",
    "\n",
    "        # Add an image_id to each subject file entry\n",
    "        image_id = 0 # represents the index of the image in the subject file \n",
    "        for d in range(len(sf_data)): \n",
    "            sf_data[d]['index'] = image_id\n",
    "            full_sf_data[d]['index'] = image_id\n",
    "            image_id+=1\n",
    "\n",
    "        subj_num = start_subjects_at+i\n",
    "        with open(os.path.join(rootdir,'subject_files',bucket,'subject_file_%d.json'%(subj_num)), 'w') as outfile: \n",
    "            print(outfile.name)\n",
    "            json.dump(sf_data, outfile)\n",
    "        with open(os.path.join(rootdir,'full_subject_files',bucket,'subject_file_%d.json'%(subj_num)), 'w') as outfile: \n",
    "            json.dump(full_sf_data, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
